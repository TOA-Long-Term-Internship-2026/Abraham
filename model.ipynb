{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7fb9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "675ae783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\VirtualUser\\\\Desktop\\\\Abraham_Internship\\\\Abraham\\\\Data'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\VirtualUser\\Desktop\\Abraham_Internship\\Abraham\\Data\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0559d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\VirtualUser\\\\Desktop\\\\Abraham_Internship\\\\Abraham\\\\Data\\\\train'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = data_path + \"\\\\train\"\n",
    "val_dir = data_path + \"\\\\validation\"\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d175e7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Cats: 9999\n",
      "Train Dogs: 9999\n",
      "Val Cats: 2500\n",
      "Val Dogs: 2500\n"
     ]
    }
   ],
   "source": [
    "traincat = os.listdir(os.path.join(train_dir, \"Cat\"))\n",
    "traindog = os.listdir(os.path.join(train_dir, \"Dog\"))\n",
    "valcat = os.listdir(os.path.join(val_dir, \"Cat\"))\n",
    "valdog = os.listdir(os.path.join(val_dir, \"Dog\"))\n",
    "print(\"Train Cats:\", len(traincat))\n",
    "print(\"Train Dogs:\", len(traindog))\n",
    "print(\"Val Cats:\", len(valcat))\n",
    "print(\"Val Dogs:\", len(valdog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0fc71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "882b0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = ImageFolder(val_dir, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "976c7717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog']\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "class_names = train_dataloader.dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e02a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No: of training images: 19998\n",
      "No: of validation images: 5000\n",
      "No: of training batches: 625\n",
      "No: of validation batches: 157\n"
     ]
    }
   ],
   "source": [
    "print(\"No: of training images:\", len(train_dataset))\n",
    "print(\"No: of validation images:\", len(val_dataset))\n",
    "print(\"No: of training batches:\", len(train_dataloader))\n",
    "print(\"No: of validation batches:\", len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b80165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "i, j = next(iter(train_dataloader))\n",
    "print(i.shape, j.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

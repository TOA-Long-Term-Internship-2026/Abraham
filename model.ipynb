{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d7fb9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "675ae783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\VirtualUser\\\\Desktop\\\\Abraham_Internship\\\\Abraham\\\\Data'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data directory path\n",
    "data_path = r\"C:\\Users\\VirtualUser\\Desktop\\Abraham_Internship\\Abraham\\Data\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0559d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\VirtualUser\\\\Desktop\\\\Abraham_Internship\\\\Abraham\\\\Data\\\\train'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and validation directories path\n",
    "train_dir = data_path + \"\\\\train\"\n",
    "val_dir = data_path + \"\\\\validation\"\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d175e7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Cats: 9999\n",
      "Train Dogs: 9999\n",
      "Val Cats: 2500\n",
      "Val Dogs: 2500\n"
     ]
    }
   ],
   "source": [
    "#Listng the number of images in each folder\n",
    "traincat = os.listdir(os.path.join(train_dir, \"Cat\"))\n",
    "traindog = os.listdir(os.path.join(train_dir, \"Dog\"))\n",
    "valcat = os.listdir(os.path.join(val_dir, \"Cat\"))\n",
    "valdog = os.listdir(os.path.join(val_dir, \"Dog\"))\n",
    "print(\"Train Cats:\", len(traincat))\n",
    "print(\"Train Dogs:\", len(traindog))\n",
    "print(\"Val Cats:\", len(valcat))\n",
    "print(\"Val Dogs:\", len(valdog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c0fc71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing/augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #Resizing the images to 224x224\n",
    "    transforms.RandomRotation(15), #Random rotation\n",
    "    transforms.RandomHorizontalFlip(), #Random horizontal flip\n",
    "    transforms.ToTensor(), #Converting the images to tensors\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2), #Color jitter that augments the brightness, contrast, saturation, and hue of the images\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #Normalizing the images by subtracting the mean and dividing by the standard deviation\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([ #validaiton doesn't need data augmentation\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "882b0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_dir, transform=train_transforms) #Creating the datasets for training and validation\n",
    "val_dataset = ImageFolder(val_dir, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "976c7717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog']\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4) #Creating the dataloaders with the datasets and batch size of 32 and num_workers of 4 for parallel processing with shuffling to randomize the order of the images\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4) #Validation doesn't need shuffling cause it's not training\n",
    "class_names = train_dataloader.dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6e02a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No: of training images: 19998\n",
      "No: of validation images: 5000\n",
      "No: of training batches: 625\n",
      "No: of validation batches: 157\n"
     ]
    }
   ],
   "source": [
    "print(\"No: of training images:\", len(train_dataset))\n",
    "print(\"No: of validation images:\", len(val_dataset))\n",
    "print(\"No: of training batches:\", len(train_dataloader))\n",
    "print(\"No: of validation batches:\", len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b80165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "i, j = next(iter(train_dataloader)) #Getting the first batch of images\n",
    "print(i.shape, j.shape) #The shape is (32, 3, 224, 224) and (32,) which denotes the number of images in the batch, the number of channels, and the size of the images and no: of images-label pairs in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "85a3abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "GPU Name: CPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\") #Checking if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6119c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VirtualUser\\Desktop\\Abraham_Internship\\Abraham\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\VirtualUser\\Desktop\\Abraham_Internship\\Abraham\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True) #Loading the pre-trained ResNet model with pretrained weights from torchvision \n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "df4e01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing every layer of the ResNet model\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "48e96cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048, 1, 1])\n",
      "tensor([[[[0.3696]],\n",
      "\n",
      "         [[0.6529]],\n",
      "\n",
      "         [[0.4742]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1274]],\n",
      "\n",
      "         [[0.5598]],\n",
      "\n",
      "         [[0.2134]]],\n",
      "\n",
      "\n",
      "        [[[0.3525]],\n",
      "\n",
      "         [[0.3176]],\n",
      "\n",
      "         [[0.4274]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5178]],\n",
      "\n",
      "         [[0.3307]],\n",
      "\n",
      "         [[0.4098]]]])\n"
     ]
    }
   ],
   "source": [
    "resnet_features = nn.Sequential(*list(resnet50.children())[:-1])\n",
    "\n",
    "#Testing the feature extraction layer\n",
    "sample_input = torch.randn(2, 3, 224, 224)  # batch of 2 images\n",
    "features = resnet_features(sample_input)\n",
    "print(features.shape) \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "accf4832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[ 0.1155, -0.1555],\n",
      "        [-0.1068, -0.0010]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "custom_classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.30),\n",
    "    nn.Linear(512, 2),\n",
    ")\n",
    "\n",
    "#Testing the custom classifier\n",
    "prob = custom_classifier(features)\n",
    "print(prob.shape)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fc1e20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[-0.0152, -0.0511],\n",
      "        [ 0.0494, -0.1888]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def model_forward (x):\n",
    "    features = resnet_features(x)\n",
    "    output = custom_classifier(features)\n",
    "    return output\n",
    "\n",
    "#Testing forward function\n",
    "sample_output = model_forward(sample_input)\n",
    "print(sample_output.shape)\n",
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "41397d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9dff8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model_forward,\n",
    "                    classifier,\n",
    "                    dataloader,\n",
    "                    loss_function,\n",
    "                    optimizer):\n",
    "\n",
    "    # Put classifier in training mode\n",
    "    classifier.train()\n",
    "\n",
    "    # Variables to track performance\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Loop through batches\n",
    "    for inputs, labels in dataloader:\n",
    "\n",
    "        # Clear old gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_forward(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate total loss\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Get predicted classes\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Count correct predictions\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "        # Count total samples\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Compute average loss\n",
    "    average_loss = total_loss / total_samples\n",
    "\n",
    "    # Compute accuracy percentage\n",
    "    accuracy = (correct_predictions / total_samples) * 100\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5ce13491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model_forward,\n",
    "                       classifier,\n",
    "                       dataloader,\n",
    "                       loss_function):\n",
    "\n",
    "    # Put classifier in evaluation mode\n",
    "    classifier.eval()\n",
    "\n",
    "    # Variables to track performance\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Loop through validation batches\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_forward(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # Accumulate total loss\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Get predicted classes\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "            # Count total samples\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Compute average loss\n",
    "    average_loss = total_loss / total_samples\n",
    "\n",
    "    # Compute accuracy percentage\n",
    "    accuracy = (correct_predictions / total_samples) * 100\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c69cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model_forward,\n",
    "        custom_classifier,\n",
    "        train_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = validate_one_epoch(\n",
    "        model_forward,\n",
    "        custom_classifier,\n",
    "        val_dataloader,\n",
    "        criterion,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch:\", epoch + 1)\n",
    "    print(\"Train Loss:\", round(train_loss, 4), \n",
    "          \"Train Accuracy:\", round(train_acc, 2), \"%\")\n",
    "    print(\"Val Loss:\", round(val_loss, 4), \n",
    "          \"Val Accuracy:\", round(val_acc, 2), \"%\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
